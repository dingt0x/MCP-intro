import json
from fastapi import FastAPI, Request, HTTPException
from fastapi.responses import HTMLResponse
from openai import OpenAI
import uvicorn
from conf import base_url, api_key, model_name, port
from ops import ops_tools ,get_server_info
from weather import get_weather,weather_tools
import asyncio
from fastapi.responses import StreamingResponse


app = FastAPI()
client = OpenAI(base_url=base_url, api_key=api_key)

chat_memory = {}
MAX_HISTORY = 20

tools = ops_tools + weather_tools

@app.post("/chat")
async def chat(request: Request):
    data = await request.json()
    user_input = data.get("message")
    session_id = data.get("session_id", "default_user")

    if session_id not in chat_memory:
        chat_memory[session_id] = []

    chat_memory[session_id].append({"role": "user", "content": user_input})

    async def event_generator():
        try:
            # 1. ç¬¬ä¸€æ¬¡è°ƒç”¨ï¼šåˆ¤æ–­æ„å›¾
            response = client.chat.completions.create(
                model=model_name,
                messages=chat_memory[session_id],
                tools=tools,
                tool_choice="auto"
            )

            response_message = response.choices[0].message

            if response_message.tool_calls:
                # å°†æ¨¡å‹çš„â€œè°ƒç”¨æ„å›¾â€åŠ å…¥å†å²
                chat_memory[session_id].append(response_message)

                # éå†æ‰€æœ‰å·¥å…·è°ƒç”¨ï¼ˆæ”¯æŒ AI ä¸€æ¬¡æ€§è°ƒç”¨å¤šä¸ªå·¥å…·ï¼‰
                for tool_call in response_message.tool_calls:
                    function_name = tool_call.function.name
                    function_args = json.loads(tool_call.function.arguments)

                    # åŠ¨æ€æ¨é€çŠ¶æ€ç»™å‰ç«¯ï¼Œå‘ŠçŸ¥æ­£åœ¨è°ƒç”¨å“ªä¸ªå·¥å…·
                    yield f"data: {json.dumps({'type': 'status', 'content': f'ğŸ› ï¸ æ­£åœ¨æ‰§è¡Œ: {function_name}...'})}\n\n"

                    # æ‰§è¡Œé€»è¾‘åˆ†æ”¯
                    if function_name == "get_weather":
                        city = function_args.get("city")
                        result = get_weather(city)
                    elif function_name == "get_server_info":
                        platform = function_args.get("platform")
                        result = get_server_info(platform)
                    else:
                        result = {"error": "æœªå®šä¹‰çš„å·¥å…·"}

                    # å°†æ‰§è¡Œç»“æœå›ä¼ ç»™å†å²è®°å½•
                    chat_memory[session_id].append({
                        "tool_call_id": tool_call.id,
                        "role": "tool",
                        "name": function_name,
                        "content": json.dumps(result, ensure_ascii=False),
                    })

                # ç¬¬äºŒæ¬¡è°ƒç”¨ï¼šè·å–æµå¼æ€»ç»“
                yield f"data: {json.dumps({'type': 'status', 'content': 'ğŸš€ æ­£åœ¨æ±‡æ€»æ•°æ®å¹¶ç”ŸæˆæŠ¥å‘Š...'})}\n\n"

                second_res = client.chat.completions.create(
                    model=model_name,
                    messages=chat_memory[session_id],
                    stream=True
                )

                full_answer = ""
                for chunk in second_res:
                    if chunk.choices and chunk.choices[0].delta.content:
                        content = chunk.choices[0].delta.content
                        full_answer += content
                        yield f"data: {json.dumps({'type': 'text', 'content': content})}\n\n"

                chat_memory[session_id].append({"role": "assistant", "content": full_answer})

            else:
                # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥æµå¼è¿”å›å†…å®¹
                # ä¸ºäº†è®©å‰ç«¯ç»Ÿä¸€å¤„ç†ï¼Œæˆ‘ä»¬ä¹Ÿåˆ†ç‰‡â€œå‡æµå¼â€æˆ–è€…ç›´æ¥å‘é€
                full_answer = response_message.content
                yield f"data: {json.dumps({'type': 'text', 'content': full_answer})}\n\n"
                chat_memory[session_id].append({"role": "assistant", "content": full_answer})

            # ä¿æŒæ»‘åŠ¨çª—å£
            if len(chat_memory[session_id]) > MAX_HISTORY:
                chat_memory[session_id] = chat_memory[session_id][-MAX_HISTORY:]

        except Exception as e:
            error_msg = f"âŒ ç³»ç»Ÿé”™è¯¯: {str(e)}"
            print(f"ğŸ”¥ {error_msg}")
            yield f"data: {json.dumps({'type': 'text', 'content': error_msg})}\n\n"

    return StreamingResponse(event_generator(), media_type="text/event-stream")

@app.get("/", response_class=HTMLResponse)
async def index():
    with open("index.html", "r", encoding="utf-8") as f:
        return f.read()

if __name__ == "__main__":
    port = int(port) + 2
    print(f"ğŸš€ Level 2 (Function Call) è¿è¡Œåœ¨: http://127.0.0.1:{port}")
    uvicorn.run(app, host="0.0.0.0", port=int(port))